# ğŸ§  LangChain RAG Chatbot (Local AI Assistant using Ollama + FAISS)

### ğŸš€ Intelligent, Offline, Document-Aware Chatbot built with LangChain, Ollama (Mistral), FAISS, and HuggingFace Embeddings

---

## ğŸ“˜ Overview

This project is a **Retrieval-Augmented Generation (RAG)** chatbot that can **read, understand, and answer questions from any set of PDF documents** â€” entirely **offline**.

It uses **LangChain for orchestration**, **FAISS** for vector search, and **Ollama (Mistral LLM)** as a local reasoning engine.
You can upload new data anytime using a **parallel Flask app**, allowing the system to continuously learn and respond intelligently from the latest context.

---

## ğŸ¯ Key Features

âœ… **Offline Intelligence** â€” No API calls or internet required; all LLM processing happens locally using Ollama.
âœ… **RAG Pipeline** â€” Combines document retrieval (FAISS) with context-aware generation (Mistral).
âœ… **Real-time Knowledge Updates** â€” Add new information dynamically through a separate web interface.
âœ… **GPU Acceleration** â€” Uses CUDA-enabled HuggingFace embeddings for lightning-fast vector operations.
âœ… **Multi-Interface Architecture** â€”

* `app.py` â†’ Chatbot interface for querying documents
* `app2.py` â†’ Input app to add new knowledge
  âœ… **Scalable Design** â€” Modular code that supports new models or embedding upgrades easily.
  âœ… **Privacy-Focused** â€” All computation and data remain on your local system.

---

## ğŸ—ï¸ Tech Stack

| Category     | Technology                                             |
| ------------ | ------------------------------------------------------ |
| Language     | Python 3.10+                                           |
| Frameworks   | Flask, LangChain                                       |
| Embeddings   | HuggingFace Sentence Transformers (`all-MiniLM-L6-v2`) |
| Vector Store | FAISS                                                  |
| LLM          | Ollama (Mistral 7B)                                    |
| GPU Support  | CUDA 12.8                                              |
| Data Format  | PDF Documents                                          |
| UI           | HTML + CSS + JS (Lightweight Frontend)                 |

---

## âš™ï¸ Architecture Overview

```
+------------------------+
|      User Query        |
+-----------+------------+
            |
            v
+------------------------+
|   Flask Chat UI (app)  |
+-----------+------------+
            |
            v
+------------------------+
| LangChain RAG Pipeline |
|  - Retrieve (FAISS)    |
|  - Augment Context     |
|  - Generate (Ollama)   |
+-----------+------------+
            |
            v
+------------------------+
|    Helpful Answer      |
+------------------------+
```

ğŸ§© Parallel app (`app2.py`) lets users insert new data via embeddings and updates FAISS vectors in real time.

---

## ğŸ“‚ Project Structure

```
githubBNMChatbot/
â”‚
â”œâ”€â”€ app.py                     # Main Flask chatbot app
â”œâ”€â”€ app2.py                    # Data ingestion web app
â”œâ”€â”€ ingest.py                  # Converts PDF data to FAISS vectors
â”œâ”€â”€ model.py                   # LangChain RAG model pipeline
â”œâ”€â”€ user.py                    # Adds new user input to FAISS DB
â”‚
â”œâ”€â”€ data/                      # Folder containing source PDFs
â”œâ”€â”€ vectorstore/               # Stores FAISS embeddings & index
â”‚
â”œâ”€â”€ static/                    # CSS, JS, images
â”œâ”€â”€ templates/                 # HTML templates
â”‚
â””â”€â”€ README.md                  # Project documentation
```

---

## ğŸ’¡ How It Works

1. **Document Ingestion**

   * PDFs in `/data/` are processed by `ingest.py`.
   * Texts are split and converted into vector embeddings using HuggingFace.
   * Stored locally in FAISS (`/vectorstore/`).

2. **Chatbot Query**

   * User asks a question through the Flask web interface.
   * FAISS retrieves the most relevant document chunks.
   * LangChain formats them into a context.
   * Ollamaâ€™s Mistral model generates the response.

3. **Dynamic Learning**

   * A separate Flask app (`app2.py`) lets users add new text inputs.
   * These are embedded and appended to the FAISS vector database.

---

## ğŸ–¥ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/yourusername/langchain-rag-chatbot.git
cd langchain-rag-chatbot
```

### 2ï¸âƒ£ Create a Virtual Environment

```bash
python -m venv .venv
.\.venv\Scripts\activate     # Windows
# or
source .venv/bin/activate    # Linux / Mac
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Install Ollama and Mistral Model

```bash
# Download and install Ollama
https://ollama.com/download

# Once installed, pull Mistral model
ollama pull mistral
```

### 5ï¸âƒ£ Ingest Your PDFs

Place your PDFs inside the `/data/` folder and run:

```bash
python ingest.py
```

### 6ï¸âƒ£ Run the Chatbot

```bash
python app.py
```

Then open [http://127.0.0.1:5000](http://127.0.0.1:5000) in your browser.

### 7ï¸âƒ£ (Optional) Run the Add-Data App

```bash
python app2.py
```

Accessible at [http://127.0.0.1:5001](http://127.0.0.1:5001)

---

## âš¡ Performance Notes

* For best speed, use **GPU embeddings** (`device='cuda'` in HuggingFace).
* Ollama automatically leverages your GPU for local inference.
* FAISS multi-threading optimized using `faiss.omp_set_num_threads(os.cpu_count())`.

---

## ğŸ”’ Security & Privacy

All processing â€” from embedding to generation â€” happens on your **local machine**.
No data is sent to the cloud, making it ideal for **confidential or enterprise datasets**.

---

## ğŸ§© Future Enhancements

* Add multi-document upload and auto-refresh.
* Support for summarization and multi-turn conversations.
* Extend LLM options (e.g., `llama3`, `phi3`, `mixtral`).
* Implement persistent session memory.
* Dockerize for easy deployment.

---

## ğŸ§‘â€ğŸ’» Author

**Developed by:** [Your Name]
**LinkedIn:** [linkedin.com/in/yourprofile](#)
**GitHub:** [github.com/yourusername](#)
**Email:** [yourname@example.com](mailto:yourname@example.com)

---

## ğŸŒŸ Acknowledgements

* [LangChain](https://www.langchain.com)
* [HuggingFace](https://huggingface.co)
* [Ollama](https://ollama.com)
* [FAISS](https://github.com/facebookresearch/faiss)
